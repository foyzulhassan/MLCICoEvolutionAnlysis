name: gst-inference CI

on:
  push:
    branches:
      - master
      - dev-*
  pull_request:
    branches:
      - dev-*

jobs:
  build_autotools:
    runs-on: ubuntu-18.04
    container: ridgerun/r2inference:v0.1.5
    env:
      PREFIX: /usr/lib/x86_64-linux-gnu/
      CFLAGS: -Werror
      CXXFLAGS: -Werror
    steps:
    - uses: actions/checkout@v2
    - name: Build backend
      run: |
        tar -C /usr/local -xzf /root/r2inference/backends/tensorflow/v1.15.0/libtensorflow-cpu-linux-x86_64-1.15.0.tar.gz
        ldconfig
    - name: Checkout r2i repo
      uses: actions/checkout@master
      with:
        repository: RidgeRun/r2inference
    - name: Build r2i
      run: |
        NOCONFIGURE=1 ./autogen.sh
        ./configure --disable-docs --enable-tensorflow
        make
        make install
    - name: Checkout gst-inference repo
      uses: actions/checkout@v2
      with:
        submodules: true
    - name: Build gst-inference
      run: |
        NOCONFIGURE=1 ./autogen.sh
        ./configure  --disable-docs --prefix $PREFIX --libdir $PREFIX
        make
    - name: Check gst-inference
      env:
        LD_LIBRARY_PATH: /usr/local/lib/
      run: make check VERBOSE=1
    - name: Install gst-inference
      run: |
        make install
    - name: Check gst-inference install
      env:
        LD_LIBRARY_PATH: /usr/local/lib/
      run: gst-inspect-1.0 inference
    - name: Run GStreamer pipeline
      env:
        ROOT: /root/r2inference/resources/InceptionV1_TensorFlow
        LD_LIBRARY_PATH: /usr/local/lib/
      run: |
        gst-launch-1.0 inceptionv1 name=net model-location=$ROOT/graph_inceptionv1_tensorflow.pb \
        backend=tensorflow labels="$(cat $ROOT/imagenet_labels.txt)" backend::input-layer=input \
        backend::output-layer=InceptionV1/Logits/Predictions/Reshape_1 multifilesrc \
        location=$ROOT/Egyptian_cat.jpg start-index=0 stop-index=0 ! jpegparse ! jpegdec ! \
        videoconvert ! videoscale ! queue ! tee name=t t. ! queue ! videoconvert ! videoscale ! \
        net.sink_model t. ! queue ! videoconvert ! net.sink_bypass  net.src_model ! fakesink \
        net.src_bypass ! queue ! inferenceoverlay thickness=2 font-scale=1 style=1 ! videoconvert ! \
        fakesink silent=false sync=false async=false -v
  build_meson:
    runs-on: ubuntu-18.04
    container: ridgerun/r2inference:v0.1.5
    env:
      PREFIX: /usr
      CFLAGS: -Werror
      CXXFLAGS: -Werror
    steps:
    - uses: actions/checkout@v2
    - name: Build backend
      run: |
        tar -C /usr/local -xzf /root/r2inference/backends/tensorflow/v1.15.0/libtensorflow-cpu-linux-x86_64-1.15.0.tar.gz
        ldconfig
    - name: Checkout r2i repo
      uses: actions/checkout@master
      with:
        repository: RidgeRun/r2inference
    - name: Build r2i
      run: |
        NOCONFIGURE=1 ./autogen.sh
        ./configure --disable-docs --enable-tensorflow
        make
        make install
    - name: Checkout gst-inference repo
      uses: actions/checkout@v2
      with:
        submodules: true
    - name: Build gst-inference
      run: |
        meson build --prefix $PREFIX -Denable-gtk-doc=false
        ninja -C build
    - name: Check gst-inference
      env:
        LD_LIBRARY_PATH: /usr/local/lib/
      run: ninja -C build test -v
    - name: Install gst-inference
      run: |
        ninja -C build install
    - name: Check gst-inference install
      env:
        LD_LIBRARY_PATH: /usr/local/lib/
      run: gst-inspect-1.0 inference
    - name: Run GStreamer pipeline
      env:
        ROOT: /root/r2inference/resources/InceptionV1_TensorFlow
        LD_LIBRARY_PATH: /usr/local/lib/
      run: |
        gst-launch-1.0 inceptionv1 name=net model-location=$ROOT/graph_inceptionv1_tensorflow.pb \
        backend=tensorflow labels="$(cat $ROOT/imagenet_labels.txt)" backend::input-layer=input \
        backend::output-layer=InceptionV1/Logits/Predictions/Reshape_1 multifilesrc \
        location=$ROOT/Egyptian_cat.jpg start-index=0 stop-index=0 ! jpegparse ! jpegdec ! \
        videoconvert ! videoscale ! queue ! tee name=t t. ! queue ! videoconvert ! videoscale ! \
        net.sink_model t. ! queue ! videoconvert ! net.sink_bypass  net.src_model ! fakesink \
        net.src_bypass ! queue ! inferenceoverlay thickness=2 font-scale=1 style=1 ! videoconvert ! \
        fakesink silent=false sync=false async=false -v