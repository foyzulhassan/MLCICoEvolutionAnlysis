name: (Auto) Tests

on:
  push:
    branches:
      - master
      - main

  pull_request:
    branches:
      - main
      - master

jobs:
  # Job (1): Run testing in parallel against multiples OSs and Python versions
  test:
    name: Test
    runs-on: ${{ matrix.os }}
    # Determines whether the entire workflow should pass/fail based on parallel jobs
    continue-on-error: ${{ matrix.ok-fail }}
    defaults:
      # This ensures each step gets properly configured bash shell for conda commands to work
      run:
        shell: bash -l {0}
    strategy:
      fail-fast: false
      matrix:
        # OSs to test
        os: [ubuntu-latest, macos-latest, windows-latest]
        # Python versions to test
        python-version: [3.7, 3.8]
        # By default everything should pass for the workflow to pass
        ok-fail:
          include:
            # Windows sometimes fails to install due to dependency changes, but
            # eventually sort themselves out. So let these tests fail
            - os: windows-latest
              python-version: 3.7
              ok-fail: true
            - os: windows-latest
              python-version: 3.8
              ok-fail: true
    steps:
      # Step up miniconda
      - name: Download and setup Miniconda
        uses: conda-incubator/setup-miniconda@v2
        with:
          miniconda-version: "latest"
          python-version: ${{ matrix.python-version }}

      # Check out latest code on github
      - name: Checkout Code
        uses: actions/checkout@v2

      # Install common sci-py packages via conda as well as testing packages and requirements
      # TODO: unpin pandas version when deepdish adds support for 1.2: https://github.com/uchicago-cs/deepdish/issues/45
      - name: Install Dependencies
        run: |
          conda activate test
          conda env list
          conda install -y pip pandas">=1.1.0,<1.2" numpy scipy matplotlib seaborn scikit-learn
          conda install -y -c conda-forge pytest pytest-xdist pytest-sugar coveralls black
          pip install . -r requirements.txt
          pip install . -r optional-dependencies.txt

      # Check code formatting
      - name: Check code formatting
        run: |
          black --version
          black --check --diff --verbose nltools

      # Actually run the tests with coverage
      - name: Run Tests
        run: |
          conda activate test
          conda env list
          coverage run --source=nltools -m pytest -rs -n auto

      # Send coverage to coveralls.io but waiting on parallelization to finish
      # Not using the official github action in the marketplace to upload because it requires a .lcov file, which pytest doesn't generate. It's just easier to use the coveralls python library which does the same thing, but works with pytest.
      - name: Upload Coverage
        # The coveralls python package has some 422 server issues with uploads from github-actions so try both service providers, for more see:
        # https://github.com/TheKevJames/coveralls-python/issues/252
        run: coveralls --service=github || coveralls --service=github-actions
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          COVERALLS_FLAG_NAME: $${{ matrix}}
          COVERALLS_PARALLEL: true

  # Job (2): Send a finish notification to coveralls.io to integrate coverage across parallel tests
  coveralls:
    name: Coveralls.io Upload
    needs: test
    runs-on: ubuntu-latest
    container: python:3-slim
    continue-on-error: true
    steps:
      - name: Finished
        run: |
          pip3 install --upgrade coveralls
          coveralls --service=github --finish || coveralls --service=github-actions --finish
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Job (3): Build docs, but don't deploy. This is effectively another layer of testing because of our sphinx-gallery auto-examples
  docs:
    name: Build docs and auto-examples
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v2

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.8"

      # - name: Upgrade pip
      #   run: |
      #     # install pip=>20.1 to use "pip cache dir"
      #     python3 -m pip install --upgrade pip

      # - name: Setup pip-cache
      #   id: pip-cache
      #   run: echo "::set-output name=dir::$(pip cache dir)"

      # - name: Cache deps
      #   uses: actions/cache@v2
      #   with:
      #     path: ${{ steps.pip-cache.outputs.dir }}
      #     key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
      #     restore-keys: |
      #       ${{ runner.os }}-pip-

      - name: Install deps
        run: |
          python3 -m pip install . -r requirements.txt
          python3 -m pip install . -r requirements-dev.txt
          python3 -m pip install . -r optional-dependencies.txt

      - name: Build docs
        run: |
          cd docs
          make clean
          make html