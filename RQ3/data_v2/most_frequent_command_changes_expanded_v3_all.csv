"('Insert', 'branches', 'master', '')",557"('Update', 'python-version', 'PYTHON-VERSION', '')",402"('Insert', 'jobs', 'jobs', '')",362"('Delete', 'jobs', 'jobs', '')",329"('Tree-Addition', 'python-version', 'PYTHON-VERSION', '')",279"('Tree-Delete', 'python-version', 'PYTHON-VERSION', '')",255"('Insert', 'push', 'branches:master', '')",166"('Tree-Addition', 'shell', 'bash', '')",158"('Tree-Addition', 'steps', 'name:Get', 'current date id:date if:failure() run:echo \\""::set-output name=date::$(date +\'%Y-%m-%d\')\\""')",127"('Insert', 'pull_request', 'branches:master', '')",124"('Update', 'run', 'run', '')",119"('Tree-Addition', 'steps', 'name:Run', 'log collector if:failure() shell:bash run:python ./scripts/container_log_collector.py\\n')",107"('Tree-Addition', 'steps', 'name:Upload', 'logs to GitHub uses:actions/upload-artifact@master if:failure() with:name:${{ matrix.os }}-${{ steps.job_name.outputs.job_name }}-logs-${{ steps.date.outputs.date }} path:./logs/${{ steps.job_name.outputs.job_name}}/')",97"('Tree-Addition', 'steps', 'name:Get', 'job name and url id:job if:failure() run:echo \\""::set-output name=job::$(echo ${{ github.job }})\\""\\necho \\""::set-output name=url::$(echo ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})\\""\\n')",93"('Insert', 'on', 'on', '')",93"('Update', 'uses', 'actions/setup-python@v2', '')",89"('Update', 'uses', 'actions/checkout@v2', '')",87"('Tree-Addition', 'if', 'steps.changes.outputs.backend', ""== 'true'"")",84"('Insert', 'steps', 'steps', '')",84"('Tree-Addition', 'steps', 'name:Mandatory', ""Container cleanup if:steps.changes.outputs.stack == 'true' continue-on-error:shell:bash run:docker rm `docker ps -aq` --force || true\\ndocker volume prune -f || true\\n"")",79"('Update', 'name', 'name', '')",75"('Update', 'if', 'failure()', '')",70"('Insert', 'on', 'workflow_run:workflows:ci', 'on ubuntu ci on centos7 ci on debian11 ci on macos ci on windows publish doc publish paper pdf CI centos7 debian11 doc MacOS Windows Test import espnet Check kaldi scripts types:requested')",62"('Insert', 'workflow_run', 'workflows:ci', 'on ubuntu ci on centos7 ci on debian11 ci on macos ci on windows publish doc publish paper pdf CI centos7 debian11 doc MacOS Windows Test import espnet Check kaldi scripts types:requested')",62"('Tree-Addition', 'if', 'failure()', '')",61"('Tree-Addition', 'steps', 'name:Job', 'Report Status if:failure() uses:ravsamhq/notify-slack-action@v2 with:status:${{ job.status }} notify_when:failure notification_title: {workflow} has {status_message} message_format:${{matrix.os}} {emoji} *{job}* {status_message} in {run_url} footer:Find the PR here ${{ steps.pull_request.outputs.url }} mention_users:U01LNCACY03,U8KUAD396,UNMQ2SJSW,U01SAESBJA0 mention_users_when:failure,warnings env:SLACK_WEBHOOK_URL:${{ secrets.ACTION_MONITORING_SLACK_WEBHOOK_URL }}')",60"('Tree-Addition', 'steps', 'name:Get', 'job name and url id:job_name if:failure() run:echo \\""::set-output name=job_name::$(echo ${{ github.job }})\\""\\necho \\""::set-output name=url::$(echo ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})\\""\\n')",59"('Tree-Addition', 'steps', 'name:Get', 'pull request url id:pull_request if:failure() run:echo \\""::set-output name=url::$(echo ${{ github.event.pull_request.html_url }})\\""\\n')",58"('Update', 'uses', 'actions/checkout@v3', '')",56"('Insert', 'on', 'push:branches:master', 'pull_request:branches:master')",55"('Update', 'uses', 'uses', '')",52"('Tree-Addition', 'if', 'steps.changes.outputs.stack', ""== 'true'"")",50"('Update', 'runs-on', '${{', 'matrix.os }}')",50"('Tree-Addition', 'on', 'push', 'pull_request')",49"('Update', 'uses', 'actions/checkout@v1', '')",49"('Insert', 'branches', 'dev', '')",48"('Update', 'id', 'job', '')",44"('Insert', 'on', 'pull_request:types:closed', 'branches:master paths:tools/** setup.py')",44"('Update', 'run', 'echo', '\\""::set-output name=job::$(echo ${{ github.job }})\\""\\necho \\""::set-output name=url::$(echo ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})\\""\\n')",44"('Insert', 'paths', 'tools/**', 'setup.py')",44"('Insert', 'with', 'with', '')",42"('Update', 'uses', 'actions/setup-python@v1', '')",41"('Insert', 'python-version', 'PYTHON-VERSION', '')",39"('Update', 'tags', 'type=raw,value=${{', 'env.GRID_VERSION }}\\ntype=raw,value=beta\\n')",36"('Update', 'working-directory', 'working-directory', '')",36"('Tree-Addition', 'on', 'push', '')",36"('Insert', 'with', 'python-version:3.x', '')",34"('Tree-Addition', 'if', 'github.event.inputs.release_platform', ""== 'REAL_PYPI'"")",34"('Insert', 'branches', 'main', '')",34"('Update', 'if', 'if', '')",33"('Insert', 'workflows', 'CI', 'centos7 debian9 doc')",32"('Tree-Addition', 'runs-on', 'ubuntu-latest', '')",32"('Insert', 'workflow_run', 'workflows:CI', 'centos7 debian9 doc types:requested')",32"('Update', 'uses', 'docker/build-push-action@v4', '')",32"('Update', 'uses', 'actions/setup-python@v4', '')",31"('Tree-Addition', 'jobs', 'cancel:runs-on:ubuntu-latest', 'steps:uses:styfle/cancel-workflow-action@0.11.0 with:workflow_id:${{ github.event.workflow.id }}')",31"('Insert', 'workflows', 'workflows', '')",31"('Insert', 'workflows', 'ci', 'on ubuntu ci on centos7 ci on debian11 ci on macos ci on windows publish doc publish paper pdf CI centos7 debian11 doc MacOS Windows Test import espnet Check kaldi scripts')",31"('Insert', 'workflows', 'publish', 'doc')",31"('Update', 'os', 'ubuntu-latest', '')",31"('Tree-Addition', 'name', 'cancel', 'workflows')",31"('Tree-Addition', 'on', 'pull_request', '')",30"('Update', 'name', 'Set', 'up Python 3.7')",30"('Update', 'tags', 'type=raw,value=${{', 'env.GRID_VERSION }}\\ntype=raw,value=latest\\n')",29"('Update', 'env', 'env', '')",29"('Insert', 'run', 'working-directory:./packages/grid', '')",29"('Insert', 'branches', '*', '')",29"('Insert', 'tags', '*', '')",28"('Update', 'pytest-modules', 'frontend', 'network security')",28"('Tree-Delete', 'continue-on-error', '', '')",28"('Tree-Addition', 'steps', 'name:Mandatory', ""Container cleanup if:steps.changes.outputs.stack == 'true' continue-on-error:shell:bash run:docker rm `docker ps -aq` --force || true\\ndocker volume prune -f || true"")",27"('Update', 'os', 'windows-latest', '')",27"('Update', 'os', 'macos-latest', '')",27"('Tree-Addition', 'runs-on', '${{', 'matrix.os }}')",27"('Update', 'with', 'with', '')",26"('Tree-Addition', 'env', 'SNYK_TOKEN:${{', 'secrets.SNYK_TOKEN }}')",26"('Update', 'if', 'github.repository', ""== 'OpenMined/PySyft'"")",26"('Insert', 'on', 'push', 'pull_request')",25"('Tree-Delete', 'notebook-test-hagrid', 'if:github.event.inputs.release_platform', '== \'REAL_PYPI\' strategy:max-parallel:99 matrix:os:ubuntu-latest python-version:3.12 runs-on:${{ matrix.os }} steps:uses:actions/checkout@v4 name:Remove unnecessary files if:matrix.os == \'ubuntu-latest\' run:sudo rm -rf /usr/share/dotnet\\nsudo rm -rf \\""$AGENT_TOOLSDIRECTORY\\""\\ndocker image prune --all --force\\ndocker builder prune --all --force\\ndocker system prune --all --force\\n name:Set up Python ${{ matrix.python-version }} uses:actions/setup-python@v5 with:python-version:${{ matrix.python-version }} name:Upgrade pip run:python -m pip install --upgrade --user pip\\n name:Get pip cache dir id:pip-cache shell:bash run:echo \\""dir=$(pip cache dir)\\"" >> $GITHUB_OUTPUT\\n name:pip cache uses:actions/cache@v4 with:path:${{ steps.pip-cache.outputs.dir }} key:${{ runner.os }}-pip-py${{ matrix.python-version }}-${{ hashFiles(\'setup.cfg\') }} restore-keys:${{ runner.os }}-pip-py${{ matrix.python-version }}-\\n name:Install Hagrid, tox and uv run:pip install -U hagrid\\npip install --upgrade pip uv==0.1.35 tox tox-uv==1.5.1\\n name:Hagrid Version run:hagrid version\\n name:Remove existing containers continue-on-error:shell:bash run:docker rm $(docker ps -aq) --force || true\\ndocker volume prune -f || true\\ndocker buildx use default || true\\n name:Launch Domain run:hagrid launch test-domain-1 to docker:8081 --tag=${{ inputs.syft_version }} --low-side\\n name:Run tests env:NODE_PORT:8081 SYFT_VERSION:${{ inputs.syft_version }} EXCLUDE_NOTEBOOKS:not 11-container-images-k8s.ipynb run:tox -e e2e.test.notebook\\n name:Run log collector timeout-minutes:5 if:failure() shell:bash run:python ./scripts/container_log_collector.py\\n name:Get job name and url id:job_name if:failure() shell:bash run:echo \\""job_name=$(echo ${{ github.job }})\\"" >> $GITHUB_OUTPUT\\necho \\""date=$(date +\'%Y-%m-%d\')\\"" >> $GITHUB_OUTPUT\\n name:Upload logs to GitHub uses:actions/upload-artifact@master if:failure() with:name:${{ matrix.os }}-${{ steps.job_name.outputs.job_name }}-logs-${{ steps.job_name.outputs.date }} path:./logs/${{ steps.job_name.outputs.job_name}}/')",25"('Insert', 'pull_request', 'pull_request', '')",25"('Update', 'run', 'pip', 'install -U hagrid\\npip install --upgrade pip uv==0.1.35 tox tox-uv==1.5.1 tox-current-env\\n')",25"('Update', 'name', 'Install', 'Hagrid, tox and uv')",25"('Update', 'uses', 'actions/cache@v3', '')",25"('Update', 'tags', 'type=raw,value=${{', 'env.GRID_VERSION }}\\ntype=raw,value=0.8.0\\n')",24"('Tree-Addition', 'defaults', 'run:shell:bash', '')",24"('Insert', 'jobs', 'formatting-check:name:Formatting', 'Check runs-on:ubuntu-latest steps:uses:actions/checkout@v2 name:Run clang-format style check for C/C++ programs. uses:jidicula/clang-format-action@v3.4.0 with:clang-format-version:11 check-path:.')",24"('Tree-Addition', 'needs', 'release-checks', '')",24"('Update', 'node-type', 'node-type', '')",24"('Insert', 'formatting-check', 'name:Formatting', 'Check runs-on:ubuntu-latest steps:uses:actions/checkout@v2 name:Run clang-format style check for C/C++ programs. uses:jidicula/clang-format-action@v3.4.0 with:clang-format-version:11 check-path:.')",24"('Insert', 'steps', 'uses:actions/checkout@v2', 'name:Run clang-format style check for C/C++ programs. uses:jidicula/clang-format-action@v3.4.0 with:clang-format-version:11 check-path:.')",24"('Insert', 'clang-format-version', '11', '')",24"('Tree-Addition', 'paths', 'packages/syft/tests/trigger/version_tests', '')",24"('Update', 'runs-on', 'ubuntu-latest', '')",24"('Insert', 'branches', 'dev', 'main 0.8')",24"('Insert', 'with', 'python-version:3.12', '')",23"('Tree-Addition', 'continue-on-error', '', '')",23"('Update', 'uses', 'actions/cache@v2', '')",23"('Update', 'shell', 'shell', '')",22"('Tree-Delete', 'shell', 'bash', '')",22"('Insert', 'with', 'context:./packages', 'file:./packages/grid/backend/backend.dockerfile platforms:${{ steps.release_metadata.outputs.release_platform }} target:backend outputs:type=image,name=openmined/syft-backend,push-by-digest=true,name-canonical=true,push=true cache-from:type=registry,ref=openmined/syft-backend:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-backend:cache-${{ steps.release_metadata.outputs.short_release_platform }},mode=max')",22"('Tree-Delete', 'if', 'failure()', '')",22"('Insert', 'pull_request', 'types:closed', 'branches:master paths:tools/** setup.py')",22"('Update', 'on', 'pull_request', '')",22"('Tree-Delete', 'os', 'windows-latest', '')",22"('Tree-Addition', 'os', 'ubuntu-latest', '')",22"('Update', 'name', '${{', 'matrix.os }}-${{ steps.job_name.outputs.job_name }}-logs-${{ steps.date.outputs.date }}')",22"('Tree-Addition', 'name', 'docker-builder', '')",22"('Tree-Addition', 'base', '${{', 'github.ref }}')",22"('Update', 'none', 'none', '')",22"('Delete', 'env', 'TORCH_VERSION:${{', 'matrix.torch-version }}')",21"('Update', 'on', 'push', '')",21"('Update', 'TWINE_USERNAME', '${{', 'secrets.PYPI_USERNAME }}')",21"('Update', 'uses', 'conda-incubator/setup-miniconda@v2', '')",21"('Update', 'uses', 'codecov/codecov-action@v1', '')",21"('Tree-Addition', 'needs', 'pretest', '')",20"('Update', 'shell', 'bash', '')",20"('Insert', 'with', 'name:wheels', 'path:dist')",20"('Update', 'id', 'id', '')",20"('Update', 'python', 'PYTHON-VERSION', '')",20"('Update', 'TWINE_PASSWORD', '${{', 'secrets.PYPI_PASSWORD }}')",20"('Insert', 'steps', 'name:Run', 'log collector if:failure() shell:bash run:python ./scripts/container_log_collector.py\\n')",20"('Insert', 'steps', 'name:Mandatory', ""Container cleanup if:steps.changes.outputs.stack == 'true' continue-on-error:shell:bash run:docker rm `docker ps -aq` --force || true\\ndocker volume prune -f || true\\n"")",20"('Insert', 'on', 'workflow_dispatch:inputs:none:description:Deploy', 'Syft Documentation required:pull_request:branches:dev paths:docs/ push:branches:dev paths:docs/')",20"('Tree-Addition', 'os', 'windows-latest', '')",20"('Update', 'os', 'ubuntu-18.04', '')",20"('Update', 'run', '#', 'install k3d\\nwget https://github.com/k3d-io/k3d/releases/download/v5.4.4/k3d-linux-amd64\\nmv k3d-linux-amd64 k3d\\nchmod +x k3d\\nexport PATH=`pwd`:$PATH\\nk3d version\\nDEVSPACE_VERSION=v5.18.5\\ncurl -sSL https://github.com/loft-sh/devspace/releases/download/${DEVSPACE_VERSION}/devspace-linux-amd64 -o ./devspace\\nchmod +x devspace\\ndevspace --version\\ntox -e stack.test.integration.k8s\\ndocker rm $(docker ps -aq) --force || true\\ndocker volume prune -f || true\\n')",20"('Update', 'run', 'bandit', '-r hagrid\\nsafety check -i 42923\\n')",20"('Update', 'image-ref', 'mongo:7.0.0', '')",20"('Update', 'branches', 'master', '')",20"('Insert', 'branches', 'branches', '')",20"('Insert', 'uses', 'actions/checkout@master', '')",20"('Tree-Addition', 'steps', 'name:Upload', 'logs to GitHub uses:actions/upload-artifact@master if:failure() with:name:${{ matrix.os }}-${{ steps.job_name.outputs.job_name }}-${{ matrix.pytest-modules }}-logs-${{ steps.date.outputs.date }} path:./logs/${{ steps.job_name.outputs.job_name}}/')",19"('Tree-Addition', 'steps', 'name:Get', 'pip cache dir id:pip-cache run:echo \\""::set-output name=dir::$(pip cache dir)\\""\\n')",19"('Insert', 'on', 'push:branches:master', '')",19"('Update', 'run', 'pip', 'install --upgrade pip uv==0.1.35 tox tox-uv==1.5.1\\nuv --version\\n')",19"('Update', 'run', 'docker', 'rm `docker ps -aq` --force || true\\ntox -e stack.test.course\\ndocker rm `docker ps -aq` --force || true')",19"('Update', 'run', 'brew', 'install libomp\\n')",19"('Tree-Delete', 'paths', 'docs/**', '')",19"('Tree-Addition', 'workflow_call', '', '')",19"('Update', 'uses', 'actions/checkout@master', '')",19"('Update', 'path', '~/.cache/pip', '')",18"('Insert', 'tags', 'v*', '')",18"('Insert', 'build-and-push-docker-images', 'strategy:matrix:runner:sh-arc-linux-x64', 'sh-arc-linux-arm64 runs-on:${{ matrix.runner }} outputs:server_version:${{ steps.release_metadata.outputs.server_version }} steps:name:Setup Python on x64 if:${{ !endsWith(matrix.runner, \'-arm64\') }} uses:actions/setup-python@v5 with:python-version:3.12 name:Install Metadata packages for arm64 if:${{ endsWith(matrix.runner, \'-arm64\') }} run:sudo apt update -y\\nsudo apt install software-properties-common -y\\nsudo apt install gcc curl -y\\nsudo apt-get install python3-dev -y\\n name:Setup Python on arm64 if:${{ endsWith(matrix.runner, \'-arm64\') }} uses:deadsnakes/action@v3.1.0 with:python-version:3.12 name:Install Git run:sudo apt-get update\\nsudo apt-get install git -y\\n uses:actions/checkout@v4 with:ref:${{ github.event.inputs.release_branch }} name:Check python version run:python --version\\npython3 --version\\nwhich python\\n name:Install dependencies run:python -m pip install --upgrade pip\\npip install uv==0.2.17 tox tox-uv==1.9.0 bump2version==1.0.1\\nuv --version\\n name:Generate Release Metadata id:release_metadata run:if [[ ${{matrix.runner}} == *\\""x64\\""* ]]; then\\n  echo \\""release_platform=linux/amd64\\"" >> $GITHUB_OUTPUT\\n  echo \\""short_release_platform=amd64\\"" >> $GITHUB_OUTPUT\\nelse\\n  echo \\""release_platform=linux/arm64\\"" >> $GITHUB_OUTPUT\\n  echo \\""short_release_platform=arm64\\"" >> $GITHUB_OUTPUT\\nfi\\necho \\""server_version=${{ github.event.inputs.release_version }}\\"" >> $GITHUB_OUTPUT\\n name:Bump to Final Release version run:python scripts/bump_version.py --bump-to-stable ${{ steps.release_metadata.outputs.server_version}}\\n name:Update Commit Hash in Syft run:python packages/syft/src/syft/util/update_commit.py packages/syft/src/syft/util/commit.py\\n name:Set up Docker Buildx uses:docker/setup-buildx-action@v3 name:Login to Docker uses:docker/login-action@v3 with:username:${{ secrets.DOCKER_LOGIN }} password:${{ secrets.DOCKER_PASSWORD }} name:Build and push `syft-backend` image to DockerHub id:syft-backend-build uses:docker/build-push-action@v6 with:context:./packages file:./packages/grid/backend/backend.dockerfile platforms:${{ steps.release_metadata.outputs.release_platform }} target:backend outputs:type=image,name=openmined/syft-backend,push-by-digest=true,name-canonical=true,push=true cache-from:type=registry,ref=openmined/syft-backend:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-backend:cache-${{ steps.release_metadata.outputs.short_release_platform }},mode=max name:Export digest for syft-backend run:mkdir -p /tmp/digests/syft-backend\\ndigest=\\""${{ steps.syft-backend-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft-backend/${digest#sha256:}\\""\\n name:Build and push `syft-frontend` image to DockerHub id:syft-frontend-build uses:docker/build-push-action@v6 with:context:./packages/grid/frontend file:./packages/grid/frontend/frontend.dockerfile platforms:${{ steps.release_metadata.outputs.release_platform }} outputs:type=image,name=openmined/syft-frontend,push-by-digest=true,name-canonical=true,push=true target:syft-ui-development cache-from:type=registry,ref=openmined/syft-frontend:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-frontend:cache-${{ steps.release_metadata.outputs.short_release_platform}},mode=max name:Export digest for syft-frontend run:mkdir -p /tmp/digests/syft-frontend\\ndigest=\\""${{ steps.syft-frontend-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft-frontend/${digest#sha256:}\\""\\n name:Build and push `syft-seaweedfs` image to DockerHub id:syft-seaweedfs-build uses:docker/build-push-action@v6 with:context:./packages/grid/seaweedfs file:./packages/grid/seaweedfs/seaweedfs.dockerfile platforms:${{ steps.release_metadata.outputs.release_platform }} outputs:type=image,name=openmined/syft-seaweedfs,push-by-digest=true,name-canonical=true,push=true cache-from:type=registry,ref=openmined/syft-seaweedfs:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-seaweedfs:cache-${{ steps.release_metadata.outputs.short_release_platform}},mode=max name:Export digest for syft-seaweedfs run:mkdir -p /tmp/digests/syft-seaweedfs\\ndigest=\\""${{ steps.syft-seaweedfs-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft-seaweedfs/${digest#sha256:}\\""\\n name:Build and push `syft-enclave-attestation` image to DockerHub if:${{ endsWith(matrix.runner, \'-x64\') }} id:syft-enclave-attestation-build uses:docker/build-push-action@v6 with:context:./packages/grid/enclave/attestation file:./packages/grid/enclave/attestation/attestation.dockerfile platforms:${{ steps.release_metadata.outputs.release_platform }} outputs:type=image,name=openmined/syft-enclave-attestation,push-by-digest=true,name-canonical=true,push=true cache-from:type=registry,ref=openmined/syft-enclave-attestation:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-enclave-attestation:cache-${{ steps.release_metadata.outputs.short_release_platform}},mode=max name:Export digest for syft-enclave-attestation if:${{ endsWith(matrix.runner, \'-x64\') }} run:mkdir -p /tmp/digests/syft-enclave-attestation\\ndigest=\\""${{ steps.syft-enclave-attestation-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft-enclave-attestation/${digest#sha256:}\\""\\n name:Build and push `syft` image to registry id:syft-build uses:docker/build-push-action@v6 with:context:./packages/ file:./packages/grid/syft-client/syft.Dockerfile outputs:type=image,name=openmined/syft-client,push-by-digest=true,name-canonical=true,push=true platforms:${{ steps.release_metadata.outputs.release_platform }} cache-from:type=registry,ref=openmined/syft-client:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-client:cache-${{ steps.release_metadata.outputs.short_release_platform }},mode=max name:Export digest for `syft` image run:mkdir -p /tmp/digests/syft\\ndigest=\\""${{ steps.syft-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft/${digest#sha256:}\\""\\n name:Upload digests uses:actions/upload-artifact@v4 with:name:digests-${{ steps.release_metadata.outputs.server_version }}-${{ steps.release_metadata.outputs.short_release_platform }} path:/tmp/digests/* if-no-files-found:error retention-days:1')",18"('Insert', 'needs', 'pre-commit', 'pretest')",18"('Tree-Addition', 'shell', 'bash', '-l {0}')",18"('Insert', 'with', 'image:mongo:7.0.0', 'args:--sarif-file-output=snyk-code.sarif')",18"('Insert', 'scan-traefik-snyk', 'permissions:contents:read', 'security-events:write actions:read runs-on:ubuntu-latest steps:name:Snyk Container test uses:snyk/actions/docker@master continue-on-error:env:SNYK_TOKEN:${{ secrets.SNYK_TOKEN }} with:image:traefik:v2.11.0 args:--sarif-file-output=snyk-code.sarif name:Post-process sarif output run:sed -i \'s/\\""security-severity\\"": \\""undefined\\""/\\""security-severity\\"": \\""0\\""/g\' snyk-code.sarif\\n name:Post-process sarif output for security severities set to \\""null\\"" run:sed -i \'s/\\""security-severity\\"": \\""null\\""/\\""security-severity\\"": \\""0\\""/g\' snyk-code.sarif\\n name:Upload result to GitHub Code Scanning uses:github/codeql-action/upload-sarif@v3 with:sarif_file:snyk-code.sarif')",18"('Delete', 'scan-traefik-snyk', 'permissions:contents:read', 'security-events:write actions:read runs-on:ubuntu-latest steps:uses:actions/checkout@v4 name:Set up Snyk CLI to check for security issues uses:snyk/actions/setup@master env:SNYK_TOKEN:${{ secrets.SNYK_TOKEN }} name:Snyk auth shell:bash run:snyk config set api=$SNYK_TOKEN env:SNYK_TOKEN:${{ secrets.SNYK_TOKEN }} name:Snyk Container test continue-on-error:shell:bash run:snyk container test traefik:v2.11.0 --sarif --sarif-file-output=snyk-code.sarif env:SNYK_TOKEN:${{ secrets.SNYK_TOKEN }} name:Upload result to GitHub Code Scanning uses:github/codeql-action/upload-sarif@v3 with:sarif_file:snyk-code.sarif')",18"('Update', 'if', 'github.repository', ""== 'OpenMined/PySyft' && (github.event.inputs.skip_tests == 'false' || github.event_name == 'schedule')"")",18"('Insert', 'steps', 'name:Setup', 'Python on x64 if:${{ !endsWith(matrix.runner, \'-arm64\') }} uses:actions/setup-python@v5 with:python-version:3.12 name:Install Metadata packages for arm64 if:${{ endsWith(matrix.runner, \'-arm64\') }} run:sudo apt update -y\\nsudo apt install software-properties-common -y\\nsudo apt install gcc curl -y\\nsudo apt-get install python3-dev -y\\n name:Setup Python on arm64 if:${{ endsWith(matrix.runner, \'-arm64\') }} uses:deadsnakes/action@v3.1.0 with:python-version:3.12 name:Install Git run:sudo apt-get update\\nsudo apt-get install git -y\\n uses:actions/checkout@v4 with:ref:${{ github.event.inputs.release_branch }} name:Check python version run:python --version\\npython3 --version\\nwhich python\\n name:Install dependencies run:python -m pip install --upgrade pip\\npip install uv==0.2.17 tox tox-uv==1.9.0 bump2version==1.0.1\\nuv --version\\n name:Generate Release Metadata id:release_metadata run:if [[ ${{matrix.runner}} == *\\""x64\\""* ]]; then\\n  echo \\""release_platform=linux/amd64\\"" >> $GITHUB_OUTPUT\\n  echo \\""short_release_platform=amd64\\"" >> $GITHUB_OUTPUT\\nelse\\n  echo \\""release_platform=linux/arm64\\"" >> $GITHUB_OUTPUT\\n  echo \\""short_release_platform=arm64\\"" >> $GITHUB_OUTPUT\\nfi\\necho \\""server_version=${{ github.event.inputs.release_version }}\\"" >> $GITHUB_OUTPUT\\n name:Bump to Final Release version run:python scripts/bump_version.py --bump-to-stable ${{ steps.release_metadata.outputs.server_version}}\\n name:Update Commit Hash in Syft run:python packages/syft/src/syft/util/update_commit.py packages/syft/src/syft/util/commit.py\\n name:Set up Docker Buildx uses:docker/setup-buildx-action@v3 name:Login to Docker uses:docker/login-action@v3 with:username:${{ secrets.DOCKER_LOGIN }} password:${{ secrets.DOCKER_PASSWORD }} name:Build and push `syft-backend` image to DockerHub id:syft-backend-build uses:docker/build-push-action@v6 with:context:./packages file:./packages/grid/backend/backend.dockerfile platforms:${{ steps.release_metadata.outputs.release_platform }} target:backend outputs:type=image,name=openmined/syft-backend,push-by-digest=true,name-canonical=true,push=true cache-from:type=registry,ref=openmined/syft-backend:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-backend:cache-${{ steps.release_metadata.outputs.short_release_platform }},mode=max name:Export digest for syft-backend run:mkdir -p /tmp/digests/syft-backend\\ndigest=\\""${{ steps.syft-backend-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft-backend/${digest#sha256:}\\""\\n name:Build and push `syft-frontend` image to DockerHub id:syft-frontend-build uses:docker/build-push-action@v6 with:context:./packages/grid/frontend file:./packages/grid/frontend/frontend.dockerfile platforms:${{ steps.release_metadata.outputs.release_platform }} outputs:type=image,name=openmined/syft-frontend,push-by-digest=true,name-canonical=true,push=true target:syft-ui-development cache-from:type=registry,ref=openmined/syft-frontend:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-frontend:cache-${{ steps.release_metadata.outputs.short_release_platform}},mode=max name:Export digest for syft-frontend run:mkdir -p /tmp/digests/syft-frontend\\ndigest=\\""${{ steps.syft-frontend-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft-frontend/${digest#sha256:}\\""\\n name:Build and push `syft-seaweedfs` image to DockerHub id:syft-seaweedfs-build uses:docker/build-push-action@v6 with:context:./packages/grid/seaweedfs file:./packages/grid/seaweedfs/seaweedfs.dockerfile platforms:${{ steps.release_metadata.outputs.release_platform }} outputs:type=image,name=openmined/syft-seaweedfs,push-by-digest=true,name-canonical=true,push=true cache-from:type=registry,ref=openmined/syft-seaweedfs:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-seaweedfs:cache-${{ steps.release_metadata.outputs.short_release_platform}},mode=max name:Export digest for syft-seaweedfs run:mkdir -p /tmp/digests/syft-seaweedfs\\ndigest=\\""${{ steps.syft-seaweedfs-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft-seaweedfs/${digest#sha256:}\\""\\n name:Build and push `syft-enclave-attestation` image to DockerHub if:${{ endsWith(matrix.runner, \'-x64\') }} id:syft-enclave-attestation-build uses:docker/build-push-action@v6 with:context:./packages/grid/enclave/attestation file:./packages/grid/enclave/attestation/attestation.dockerfile platforms:${{ steps.release_metadata.outputs.release_platform }} outputs:type=image,name=openmined/syft-enclave-attestation,push-by-digest=true,name-canonical=true,push=true cache-from:type=registry,ref=openmined/syft-enclave-attestation:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-enclave-attestation:cache-${{ steps.release_metadata.outputs.short_release_platform}},mode=max name:Export digest for syft-enclave-attestation if:${{ endsWith(matrix.runner, \'-x64\') }} run:mkdir -p /tmp/digests/syft-enclave-attestation\\ndigest=\\""${{ steps.syft-enclave-attestation-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft-enclave-attestation/${digest#sha256:}\\""\\n name:Build and push `syft` image to registry id:syft-build uses:docker/build-push-action@v6 with:context:./packages/ file:./packages/grid/syft-client/syft.Dockerfile outputs:type=image,name=openmined/syft-client,push-by-digest=true,name-canonical=true,push=true platforms:${{ steps.release_metadata.outputs.release_platform }} cache-from:type=registry,ref=openmined/syft-client:cache-${{ steps.release_metadata.outputs.short_release_platform }} cache-to:type=registry,ref=openmined/syft-client:cache-${{ steps.release_metadata.outputs.short_release_platform }},mode=max name:Export digest for `syft` image run:mkdir -p /tmp/digests/syft\\ndigest=\\""${{ steps.syft-build.outputs.digest }}\\""\\ntouch \\""/tmp/digests/syft/${digest#sha256:}\\""\\n name:Upload digests uses:actions/upload-artifact@v4 with:name:digests-${{ steps.release_metadata.outputs.server_version }}-${{ steps.release_metadata.outputs.short_release_platform }} path:/tmp/digests/* if-no-files-found:error retention-days:1')",18"('Insert', 'steps', 'name:Permission', 'to home directory run:sudo chown -R $USER:$USER $HOME\\n uses:actions/checkout@v4 with:token:${{ secrets.SYFT_BOT_COMMIT_TOKEN }} ref:${{ github.event.inputs.release_branch }} name:Remove unnecessary files run:sudo rm -rf /usr/share/dotnet\\nsudo rm -rf \\""$AGENT_TOOLSDIRECTORY\\""\\ndocker image prune --all --force\\ndocker builder prune --all --force\\ndocker system prune --all --force\\n name:Set up Python uses:actions/setup-python@v5 with:python-version:3.12 name:Install dependencies run:python -m pip install --upgrade pip\\npip install uv==0.2.17 tox tox-uv==1.9.0 setuptools wheel twine bump2version PyYAML\\nuv --version\\n name:Bump to Final Release version run:python scripts/bump_version.py --bump-to-stable ${{ needs.merge-docker-images.outputs.server_version }}\\n name:Update Commit Hash in Syft run:python packages/syft/src/syft/util/update_commit.py packages/syft/src/syft/util/commit.py\\n name:Build Helm Chart shell:bash run:# install k3d\\nK3D_VERSION=v5.6.3\\nwget https://github.com/k3d-io/k3d/releases/download/${K3D_VERSION}/k3d-linux-amd64\\nmv k3d-linux-amd64 k3d\\nchmod +x k3d\\nexport PATH=`pwd`:$PATH\\nk3d version\\n\\n#Install Devspace\\nDEVSPACE_VERSION=v6.3.12\\ncurl -sSL https://github.com/loft-sh/devspace/releases/download/${DEVSPACE_VERSION}/devspace-linux-amd64 -o ./devspace\\nchmod +x devspace\\ndevspace version\\n\\n# Install helm\\ncurl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\\nhelm version\\n\\ntox -e syft.build.helm\\ntox -e syft.package.helm\\n name:Linting run:tox -e lint || true\\n name:Manual Build and Publish run:tox -e syft.publish\\nif [[ \\""${{ github.event.inputs.release_platform }}\\"" == \\""TEST_PYPI\\"" ]]; then\\n  twine upload -r testpypi -u __token__ -p ${{ secrets.OM_SYFT_TEST_PYPI_TOKEN }} packages/syft/dist/*\\nfi\\n name:Checkout to gh-pages uses:actions/checkout@v4 with:ref:gh-pages token:${{ secrets.SYFT_BOT_COMMIT_TOKEN }} path:ghpages name:Copy helm repo files from Syft Repo run:rm -rf ghpages/helm/*\\ncp -R packages/grid/helm/repo/. ghpages/helm/\\n name:Commit changes to gh-pages uses:EndBug/add-and-commit@v9 with:author_name:${{ secrets.OM_BOT_NAME }} author_email:${{ secrets.OM_BOT_EMAIL }} message:Update Helm package from Syft Repo add:helm/ push:origin gh-pages cwd:./ghpages/')",18"('Insert', 'steps', 'name:Snyk', 'Container test uses:snyk/actions/docker@master continue-on-error:env:SNYK_TOKEN:${{ secrets.SNYK_TOKEN }} with:image:traefik:v2.11.0 args:--sarif-file-output=snyk-code.sarif name:Post-process sarif output run:sed -i \'s/\\""security-severity\\"": \\""undefined\\""/\\""security-severity\\"": \\""0\\""/g\' snyk-code.sarif\\n name:Post-process sarif output for security severities set to \\""null\\"" run:sed -i \'s/\\""security-severity\\"": \\""null\\""/\\""security-severity\\"": \\""0\\""/g\' snyk-code.sarif\\n name:Upload result to GitHub Code Scanning uses:github/codeql-action/upload-sarif@v3 with:sarif_file:snyk-code.sarif')",18"('Delete', 'steps', 'name:Snyk', 'auth shell:bash run:snyk config set api=$SNYK_TOKEN env:SNYK_TOKEN:${{ secrets.SNYK_TOKEN }}')",18"('Delete', 'steps', 'uses:actions/checkout@v4', 'name:Set up Snyk CLI to check for security issues uses:snyk/actions/setup@master env:SNYK_TOKEN:${{ secrets.SNYK_TOKEN }} name:Snyk auth shell:bash run:snyk config set api=$SNYK_TOKEN env:SNYK_TOKEN:${{ secrets.SNYK_TOKEN }} name:Snyk Container test continue-on-error:shell:bash run:snyk container test traefik:v2.11.0 --sarif --sarif-file-output=snyk-code.sarif env:SNYK_TOKEN:${{ secrets.SNYK_TOKEN }} name:Upload result to GitHub Code Scanning uses:github/codeql-action/upload-sarif@v3 with:sarif_file:snyk-code.sarif')",18"('Tree-Addition', 'steps', 'name:Run', ""syft backend base image building test if:steps.changes.outputs.stack == 'true' timeout-minutes:60 run:tox -e backend.test.basecpu\\n"")",18"('Tree-Addition', 'steps', 'name:Set', 'Grid package version run:echo \\""GRID_VERSION=$(python packages/grid/VERSION)\\"" >> $GITHUB_ENV')",18"('Tree-Addition', 'steps', 'name:Upload', 'logs to GitHub uses:actions/upload-artifact@master if:failure() with:name:${{ steps.job_name.outputs.job_name }}-logs-${{ steps.date.outputs.date }} path:./logs/${{ steps.job_name.outputs.job_name}}/')",18"('Tree-Addition', 'cache', 'pip', '')",18"('Update', 'run', 'pip', 'install --upgrade pip uv==0.1.28 tox tox-uv==1.5.1\\nuv --version\\n')",18"('Tree-Addition', 'name', 'Snyk', 'Container test')",18"('Insert', 'deploy-syft', 'needs:merge-docker-images', 'if:always() &&  needs.merge-docker-images.result == \'success\' runs-on:ubuntu-latest steps:name:Permission to home directory run:sudo chown -R $USER:$USER $HOME\\n uses:actions/checkout@v4 with:token:${{ secrets.SYFT_BOT_COMMIT_TOKEN }} ref:${{ github.event.inputs.release_branch }} name:Remove unnecessary files run:sudo rm -rf /usr/share/dotnet\\nsudo rm -rf \\""$AGENT_TOOLSDIRECTORY\\""\\ndocker image prune --all --force\\ndocker builder prune --all --force\\ndocker system prune --all --force\\n name:Set up Python uses:actions/setup-python@v5 with:python-version:3.12 name:Install dependencies run:python -m pip install --upgrade pip\\npip install uv==0.2.17 tox tox-uv==1.9.0 setuptools wheel twine bump2version PyYAML\\nuv --version\\n name:Bump to Final Release version run:python scripts/bump_version.py --bump-to-stable ${{ needs.merge-docker-images.outputs.server_version }}\\n name:Update Commit Hash in Syft run:python packages/syft/src/syft/util/update_commit.py packages/syft/src/syft/util/commit.py\\n name:Build Helm Chart shell:bash run:# install k3d\\nK3D_VERSION=v5.6.3\\nwget https://github.com/k3d-io/k3d/releases/download/${K3D_VERSION}/k3d-linux-amd64\\nmv k3d-linux-amd64 k3d\\nchmod +x k3d\\nexport PATH=`pwd`:$PATH\\nk3d version\\n\\n#Install Devspace\\nDEVSPACE_VERSION=v6.3.12\\ncurl -sSL https://github.com/loft-sh/devspace/releases/download/${DEVSPACE_VERSION}/devspace-linux-amd64 -o ./devspace\\nchmod +x devspace\\ndevspace version\\n\\n# Install helm\\ncurl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\\nhelm version\\n\\ntox -e syft.build.helm\\ntox -e syft.package.helm\\n name:Linting run:tox -e lint || true\\n name:Manual Build and Publish run:tox -e syft.publish\\nif [[ \\""${{ github.event.inputs.release_platform }}\\"" == \\""TEST_PYPI\\"" ]]; then\\n  twine upload -r testpypi -u __token__ -p ${{ secrets.OM_SYFT_TEST_PYPI_TOKEN }} packages/syft/dist/*\\nfi\\n name:Checkout to gh-pages uses:actions/checkout@v4 with:ref:gh-pages token:${{ secrets.SYFT_BOT_COMMIT_TOKEN }} path:ghpages name:Copy helm repo files from Syft Repo run:rm -rf ghpages/helm/*\\ncp -R packages/grid/helm/repo/. ghpages/helm/\\n name:Commit changes to gh-pages uses:EndBug/add-and-commit@v9 with:author_name:${{ secrets.OM_BOT_NAME }} author_email:${{ secrets.OM_BOT_EMAIL }} message:Update Helm package from Syft Repo add:helm/ push:origin gh-pages cwd:./ghpages/')",18"('Insert', 'branches', 'dev', 'main 0.6.0')",18"('Insert', 'branches', 'master', 'github-actions-test')",18"('Tree-Addition', 'timeout-minutes', '30', '')",17"('Tree-Addition', 'release_platform', 'description:Release', 'Platform required:type:choice options:REAL_PYPI TEST_PYPI')",17"('Tree-Addition', 'release_platform', 'description:Release', 'Platform required:type:string default:REAL_PYPI')",17"('Insert', 'pull_request', 'branches:*', '')",17"('Tree-Delete', 'steps', 'name:Build', 'and push `grid-headscale` image to registry uses:docker/build-push-action@v5 with:context:./packages/grid/vpn file:./packages/grid/vpn/headscale.dockerfile push:tags:${{ secrets.ACR_SERVER }}/openmined/grid-headscale:dev\\n${{ secrets.ACR_SERVER }}/openmined/grid-headscale:dev-${{ github.sha }}\\n${{ secrets.ACR_SERVER }}/openmined/grid-headscale:${{ steps.grid.outputs.GRID_VERSION }}\\n')",17"('Tree-Delete', 'steps', 'name:Build', 'and push `grid-tailscale` image to registry uses:docker/build-push-action@v5 with:context:./packages/grid/vpn file:./packages/grid/vpn/tailscale.dockerfile push:tags:${{ secrets.ACR_SERVER }}/openmined/grid-tailscale:dev\\n${{ secrets.ACR_SERVER }}/openmined/grid-tailscale:dev-${{ github.sha }}\\n${{ secrets.ACR_SERVER }}/openmined/grid-tailscale:${{ steps.grid.outputs.GRID_VERSION }}\\n')",17"('Tree-Delete', 'steps', 'name:Build', 'and push `grid-vpn-iptables` image to registry uses:docker/build-push-action@v5 with:context:./packages/grid/vpn file:./packages/grid/vpn/iptables.dockerfile push:tags:${{ secrets.ACR_SERVER }}/openmined/grid-vpn-iptables:dev\\n${{ secrets.ACR_SERVER }}/openmined/grid-vpn-iptables:dev-${{ github.sha }}\\n${{ secrets.ACR_SERVER }}/openmined/grid-vpn-iptables:${{ steps.grid.outputs.GRID_VERSION }}\\n')",17"('Update', 'run', 'pip', 'install syft==${{ inputs.syft_version }}\\n')",17"('Update', 'run', 'tox', '-e syft.test.helm')",17"('Insert', 'jobs', 'build:name:Build', 'fate client and fate_test strategy:fail-fast:runs-on:ubuntu-latest steps:uses:actions/checkout@v2 name:Extract version and name shell:bash run:# extract version and name from patterm: pypi/<version>/<name>\\necho ::set-output name=version::$(echo ${GITHUB_REF} | sed -E -e \'s/refs\\\\/heads\\\\/pypi\\\\/(.*)\\\\/(develop|release)/\\\\1/g\')\\necho ::set-output name=name::$(echo ${GITHUB_REF} | sed -E -e \'s/refs\\\\/heads\\\\/pypi\\\\/(.*)\\\\/(develop|release)/\\\\2/g\')\\n id:extract uses:actions/setup-python@v2 with:python-version:3.6 name:Prepare poetry uses:abatilo/actions-poetry@v2.0.0 with:poetry-version:1.1.6 name:Build fate_client run:cd python/fate_client\\nrm -f setup.py\\n# clear README.rst\\necho \\""# fate client\\"" > README.rst\\n# bump fate client version\\npoetry version ${{steps.extract.outputs.version}}\\n# build package, saved in dist/\\npoetry build\\n name:Build fate_test run:cd python/fate_test &&\\n# clear README.rst\\necho \\""# fate test\\"" > README.rst\\n# bump fate test version\\npoetry version ${{steps.extract.outputs.version}}\\n# update dependency version\\nsed -E -i \\""s/(fate_client\\\\s*=\\\\s*)(.*)/\\\\1\\\\\\""${{steps.extract.outputs.version}}\\\\\\""/g\\"" pyproject.toml\\ncat pyproject.toml\\n# build package, saved in dist/\\npoetry build\\n name:List dist files run:ls -lh python/fate_client/dist/ python/fate_test/dist/ name:Twine check run:pip install -U twine\\ntwine check python/fate_client/dist/*\\ntwine check python/fate_test/dist/*\\n name:Upload to artifact uses:actions/upload-artifact@v2 with:path:python/fate_client/dist/*\\npython/fate_test/dist/*\\n name:Test Install run:pip install -U pip\\npip install python/fate_client/dist/fate_client-${{steps.extract.outputs.version}}.tar.gz\\npip install python/fate_test/dist/fate_test-${{steps.extract.outputs.version}}.tar.gz\\n name:Upload to PyPI Test if:${{ steps.extract.outputs.name == \'develop\' }} run:twine upload --repository testpypi python/fate_client/dist/*\\ntwine upload --repository testpypi python/fate_test/dist/*\\n env:TWINE_USERNAME:__token__ TWINE_PASSWORD:${{ secrets.pypitest_token }} name:Upload to PyPI if:${{ steps.extract.outputs.name == \'release\' }} run:twine upload python/fate_client/dist/*\\ntwine upload python/fate_test/dist/*\\n env:TWINE_USERNAME:__token__ TWINE_PASSWORD:${{ secrets.pypi_token }}')",16"('Tree-Addition', 'jobs', 'cancel:runs-on:ubuntu-latest', 'steps:uses:styfle/cancel-workflow-action@0.9.1 with:workflow_id:${{ github.event.workflow.id }}')",16"('Insert', 'pr-tests-notebook-scenario-k8s', 'strategy:max-parallel:99', 'matrix:os:ubuntu-latest python-version:3.12 fail-fast:runs-on:${{matrix.os}} steps:name:Permission to home directory run:sudo chown -R $USER:$USER $HOME\\n uses:actions/checkout@v4 name:Check for file changes uses:dorny/paths-filter@v3 id:changes with:base:${{ github.ref }} token:${{ github.token }} filters:.github/file-filters.yml name:Set up Python ${{ matrix.python-version }} uses:actions/setup-python@v5 if:steps.changes.outputs.stack == \'true\' with:python-version:${{ matrix.python-version }} name:Add K3d Registry run:sudo python ./scripts/patch_hosts.py --add-k3d-registry\\n name:Free Disk Space (Ubuntu) uses:jlumbroso/free-disk-space@main with:tool-cache:large-packages:name:Remove unnecessary files if:matrix.os == \'ubuntu-latest\' run:sudo rm -rf /usr/share/dotnet\\nsudo rm -rf \\""$AGENT_TOOLSDIRECTORY\\""\\ndocker image prune --all --force\\ndocker builder prune --all --force\\ndocker system prune --all --force\\n name:Install pip dependencies if:steps.changes.outputs.stack == \'true\' run:python -m pip install --upgrade pip\\npip install uv==0.2.17 tox==4.16.0 tox-uv==1.9.0\\nuv --version\\n name:Get uv cache dir if:steps.changes.outputs.stack == \'true\' id:pip-cache shell:bash run:echo \\""dir=$(uv cache dir)\\"" >> $GITHUB_OUTPUT\\n name:Load github cache uses:actions/cache@v4 if:steps.changes.outputs.stack == \'true\' with:path:${{ steps.pip-cache.outputs.dir }} key:${{ runner.os }}-uv-py${{ matrix.python-version }} restore-keys:${{ runner.os }}-uv-py${{ matrix.python-version }}\\n name:Install kubectl if:steps.changes.outputs.stack == \'true\' run:# cleanup apt version\\nsudo apt remove kubectl || true\\n# install kubectl 1.27\\ncurl -LO https://dl.k8s.io/release/v1.27.2/bin/linux/amd64/kubectl\\nchmod +x kubectl\\nsudo install kubectl /usr/local/bin;\\n name:Install helm if:steps.changes.outputs.stack == \'true\' run:# install helm\\ncurl  -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\\nchmod 700 get_helm.sh\\n./get_helm.sh\\n name:Run Notebooks Tests if:steps.changes.outputs.stack == \'true\' timeout-minutes:60 env:GITHUB_CI:shell:bash run:K3D_VERSION=v5.6.3\\nDEVSPACE_VERSION=v6.3.12\\n# install k3d\\nwget https://github.com/k3d-io/k3d/releases/download/${K3D_VERSION}/k3d-linux-amd64\\nmv k3d-linux-amd64 k3d\\nchmod +x k3d\\nexport PATH=`pwd`:$PATH\\nk3d version\\ncurl -sSL https://github.com/loft-sh/devspace/releases/download/${DEVSPACE_VERSION}/devspace-linux-amd64 -o ./devspace\\nchmod +x devspace\\ndevspace version\\ntox -e stack.test.notebook.scenario.k8s\\n name:Get current timestamp id:date if:failure() shell:bash run:echo \\""date=$(date +%s)\\"" >> $GITHUB_OUTPUT name:Collect logs from k3d if:steps.changes.outputs.stack == \'true\' && failure() shell:bash run:mkdir -p ./k8s-logs\\nkubectl describe all -A --context k3d-test-datasite-1 --namespace syft > ./k8s-logs/test-datasite-1-desc-${{ steps.date.outputs.date }}.txt\\nkubectl logs -l app.kubernetes.io/name!=random --prefix=true --context k3d-test-datasite-1 --namespace syft > ./k8s-logs/test-datasite-1-logs-${{ steps.date.outputs.date }}.txt\\nls -la ./k8s-logs\\n name:Upload logs to GitHub uses:actions/upload-artifact@master if:steps.changes.outputs.stack == \'true\' && failure() with:name:k8s-logs-notebook-${{ matrix.os }}-${{ steps.date.outputs.date }} path:./k8s-logs/ name:Cleanup k3d if:steps.changes.outputs.stack == \'true\' && failure() shell:bash run:export PATH=`pwd`:$PATH\\nk3d cluster delete test-datasite-1 || true\\nk3d registry delete k3d-registry.localhost || true\\n')",16"('Insert', 'env', 'TWINE_USERNAME:__token__', 'TWINE_PASSWORD:${{ secrets.pypitest_token }}')",16"('Insert', 'with', 'path:python/fate_client/dist/*\\npython/fate_test/dist/*\\n', '')",16"('Tree-Addition', 'if', 'github.ref', ""== 'refs/heads/dev' || github.event.inputs.deploy-helm == 'true'"")",16"('Update', 'if', 'steps.changes.outputs.backend', ""== 'true'"")",16"('Insert', 'pull_request', 'branches:master', 'paths-ignore:docs/** README.rst LICENSE.md .deepsource.toml .gitignore')",16"('Update', 'IMAGE_URI', 'IMAGE_URI', '')",16"('Insert', 'steps', 'name:Permission', 'to home directory run:sudo chown -R $USER:$USER $HOME\\n uses:actions/checkout@v4 name:Check for file changes uses:dorny/paths-filter@v3 id:changes with:base:${{ github.ref }} token:${{ github.token }} filters:.github/file-filters.yml name:Set up Python ${{ matrix.python-version }} uses:actions/setup-python@v5 if:steps.changes.outputs.stack == \'true\' with:python-version:${{ matrix.python-version }} name:Add K3d Registry run:sudo python ./scripts/patch_hosts.py --add-k3d-registry\\n name:Free Disk Space (Ubuntu) uses:jlumbroso/free-disk-space@main with:tool-cache:large-packages:name:Remove unnecessary files if:matrix.os == \'ubuntu-latest\' run:sudo rm -rf /usr/share/dotnet\\nsudo rm -rf \\""$AGENT_TOOLSDIRECTORY\\""\\ndocker image prune --all --force\\ndocker builder prune --all --force\\ndocker system prune --all --force\\n name:Install pip dependencies if:steps.changes.outputs.stack == \'true\' run:python -m pip install --upgrade pip\\npip install uv==0.2.17 tox==4.16.0 tox-uv==1.9.0\\nuv --version\\n name:Get uv cache dir if:steps.changes.outputs.stack == \'true\' id:pip-cache shell:bash run:echo \\""dir=$(uv cache dir)\\"" >> $GITHUB_OUTPUT\\n name:Load github cache uses:actions/cache@v4 if:steps.changes.outputs.stack == \'true\' with:path:${{ steps.pip-cache.outputs.dir }} key:${{ runner.os }}-uv-py${{ matrix.python-version }} restore-keys:${{ runner.os }}-uv-py${{ matrix.python-version }}\\n name:Install kubectl if:steps.changes.outputs.stack == \'true\' run:# cleanup apt version\\nsudo apt remove kubectl || true\\n# install kubectl 1.27\\ncurl -LO https://dl.k8s.io/release/v1.27.2/bin/linux/amd64/kubectl\\nchmod +x kubectl\\nsudo install kubectl /usr/local/bin;\\n name:Install helm if:steps.changes.outputs.stack == \'true\' run:# install helm\\ncurl  -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\\nchmod 700 get_helm.sh\\n./get_helm.sh\\n name:Run Notebooks Tests if:steps.changes.outputs.stack == \'true\' timeout-minutes:60 env:GITHUB_CI:shell:bash run:K3D_VERSION=v5.6.3\\nDEVSPACE_VERSION=v6.3.12\\n# install k3d\\nwget https://github.com/k3d-io/k3d/releases/download/${K3D_VERSION}/k3d-linux-amd64\\nmv k3d-linux-amd64 k3d\\nchmod +x k3d\\nexport PATH=`pwd`:$PATH\\nk3d version\\ncurl -sSL https://github.com/loft-sh/devspace/releases/download/${DEVSPACE_VERSION}/devspace-linux-amd64 -o ./devspace\\nchmod +x devspace\\ndevspace version\\ntox -e stack.test.notebook.scenario.k8s\\n name:Get current timestamp id:date if:failure() shell:bash run:echo \\""date=$(date +%s)\\"" >> $GITHUB_OUTPUT name:Collect logs from k3d if:steps.changes.outputs.stack == \'true\' && failure() shell:bash run:mkdir -p ./k8s-logs\\nkubectl describe all -A --context k3d-test-datasite-1 --namespace syft > ./k8s-logs/test-datasite-1-desc-${{ steps.date.outputs.date }}.txt\\nkubectl logs -l app.kubernetes.io/name!=random --prefix=true --context k3d-test-datasite-1 --namespace syft > ./k8s-logs/test-datasite-1-logs-${{ steps.date.outputs.date }}.txt\\nls -la ./k8s-logs\\n name:Upload logs to GitHub uses:actions/upload-artifact@master if:steps.changes.outputs.stack == \'true\' && failure() with:name:k8s-logs-notebook-${{ matrix.os }}-${{ steps.date.outputs.date }} path:./k8s-logs/ name:Cleanup k3d if:steps.changes.outputs.stack == \'true\' && failure() shell:bash run:export PATH=`pwd`:$PATH\\nk3d cluster delete test-datasite-1 || true\\nk3d registry delete k3d-registry.localhost || true\\n')",16"('Tree-Addition', 'steps', 'name:Get', 'current date id:date if:failure() shell:bash run:echo \\""::set-output name=date::$(date +\'%Y-%m-%d\')\\""')",16"('Insert', 'on', 'workflow_call:push:branches:dev', 'main 0.8 test')",16"('Insert', 'on', 'push:branches:dev', 'paths:.github/workflows/syft-*.yml packages/syft/**.py')",16"('Insert', 'on', 'workflow_run:workflows:CI', 'centos7 debian9 doc types:requested')",16"('Insert', 'issue_comment', 'types:created', 'edited')",16"('Update', 'key', '${{', ""runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}"")",16"('Update', 'run', 'pip', 'install --upgrade tox\\n')",16"('Tree-Addition', 'name', 'Cancel', '')",16"('Insert', 'types', 'created', 'edited')",16"('Update', 'runs-on', 'om-ci-16vcpu-ubuntu2204', '')",16"('Insert', 'push', 'branches:master', 'dev')",16"('Insert', 'push', 'branches:master', 'github-actions-test paths-ignore:docs/** README.rst LICENSE.md .deepsource.toml .gitignore')",16"('Insert', 'branches', 'dev', 'main 0.8 test')",16"('Insert', 'build', 'name:Build', 'fate client and fate_test strategy:fail-fast:runs-on:ubuntu-latest steps:uses:actions/checkout@v2 name:Extract version and name shell:bash run:# extract version and name from patterm: pypi/<version>/<name>\\necho ::set-output name=version::$(echo ${GITHUB_REF} | sed -E -e \'s/refs\\\\/heads\\\\/pypi\\\\/(.*)\\\\/(develop|release)/\\\\1/g\')\\necho ::set-output name=name::$(echo ${GITHUB_REF} | sed -E -e \'s/refs\\\\/heads\\\\/pypi\\\\/(.*)\\\\/(develop|release)/\\\\2/g\')\\n id:extract uses:actions/setup-python@v2 with:python-version:3.6 name:Prepare poetry uses:abatilo/actions-poetry@v2.0.0 with:poetry-version:1.1.6 name:Build fate_client run:cd python/fate_client\\nrm -f setup.py\\n# clear README.rst\\necho \\""# fate client\\"" > README.rst\\n# bump fate client version\\npoetry version ${{steps.extract.outputs.version}}\\n# build package, saved in dist/\\npoetry build\\n name:Build fate_test run:cd python/fate_test &&\\n# clear README.rst\\necho \\""# fate test\\"" > README.rst\\n# bump fate test version\\npoetry version ${{steps.extract.outputs.version}}\\n# update dependency version\\nsed -E -i \\""s/(fate_client\\\\s*=\\\\s*)(.*)/\\\\1\\\\\\""${{steps.extract.outputs.version}}\\\\\\""/g\\"" pyproject.toml\\ncat pyproject.toml\\n# build package, saved in dist/\\npoetry build\\n name:List dist files run:ls -lh python/fate_client/dist/ python/fate_test/dist/ name:Twine check run:pip install -U twine\\ntwine check python/fate_client/dist/*\\ntwine check python/fate_test/dist/*\\n name:Upload to artifact uses:actions/upload-artifact@v2 with:path:python/fate_client/dist/*\\npython/fate_test/dist/*\\n name:Test Install run:pip install -U pip\\npip install python/fate_client/dist/fate_client-${{steps.extract.outputs.version}}.tar.gz\\npip install python/fate_test/dist/fate_test-${{steps.extract.outputs.version}}.tar.gz\\n name:Upload to PyPI Test if:${{ steps.extract.outputs.name == \'develop\' }} run:twine upload --repository testpypi python/fate_client/dist/*\\ntwine upload --repository testpypi python/fate_test/dist/*\\n env:TWINE_USERNAME:__token__ TWINE_PASSWORD:${{ secrets.pypitest_token }} name:Upload to PyPI if:${{ steps.extract.outputs.name == \'release\' }} run:twine upload python/fate_client/dist/*\\ntwine upload python/fate_test/dist/*\\n env:TWINE_USERNAME:__token__ TWINE_PASSWORD:${{ secrets.pypi_token }}')",16"('Update', 'uses', 'aquasecurity/trivy-action@7b7aa264d83dc58691451798b4d117d53d21edfe', '')",16"('Update', 'uses', 'snyk/actions/setup@806182742461562b67788a64410098c9d9b96adb', '')",16"('Insert', 'steps', 'id:review', 'uses:microsoft/gpt-review@v0.9.2 with:GITHUB_TOKEN:${{ secrets.GITHUB_TOKEN }} AZURE_OPENAI_API:${{ secrets.AZURE_OPENAI_API }} AZURE_OPENAI_API_KEY:${{ secrets.AZURE_OPENAI_API_KEY }}')",15"('Insert', 'matrix', 'matrix', '')",15